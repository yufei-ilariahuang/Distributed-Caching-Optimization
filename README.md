# Distributed Caching System in Go

This project is a distributed caching system built in Go, inspired by Google's GroupCache. It is designed to be high-performance, fault-tolerant, and resilient against common caching issues like cache stampedes.
```bash
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CLIENT (curl/browser)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚ HTTP Request
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           API Server (Frontend) - Port 9999                  â”‚
â”‚              http://localhost:9999/api?key=Tom               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚ gee.Get("Tom")
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GeeCache Group (Logic Layer)              â”‚
â”‚                  Handles: routing, singleflight              â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                              â”‚
       â”‚ Local cache hit?             â”‚ Cache miss?
       â–¼                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Local LRU      â”‚        â”‚    Peer Discovery                 â”‚
â”‚  mainCache      â”‚        â”‚    (Consistent Hashing)           â”‚
â”‚  (in-memory)    â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
                                      â”‚ Which peer owns key?
                                      â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚  Do I own this key?         â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚           â”‚
                    YES: Load local â”‚         â”‚ NO: Fetch from peer
                                  â–¼           â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚  Getter      â”‚  â”‚  HTTP GET to Peer   â”‚
                        â”‚  (SlowDB)    â”‚  â”‚  e.g., Node 8001    â”‚
                        â”‚  db[key]     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â”‚ In-memory map
                             â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  var db = map[...]  â”‚
                    â”‚  Tom:  "630"        â”‚
                    â”‚  Jack: "589"        â”‚
                    â”‚  Sam:  "567"        â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```
## Features

*   **LRU Cache**: A core in-memory LRU (Least Recently Used) cache for efficient key eviction.
*   **Distributed Nodes**: The cache is distributed across multiple nodes, with each node responsible for a portion of the keys.
*   **Consistent Hashing**: Uses a consistent hashing algorithm to map keys to nodes, ensuring minimal data redistribution when nodes are added or removed.
*   **Cache Stampede Prevention**: Implements the `single-flight` pattern to prevent the "thundering herd" problem (cache breakdown) where multiple requests for the same uncached key overwhelm the backend data source.
*   **Peer-to-Peer Communication**: Nodes communicate directly with each other over HTTP to retrieve data owned by other peers.

---

## Core Concepts & Data Structures

### 1. LRU Cache

The foundation of each cache node is a thread-safe LRU cache. It uses a standard combination of a hash map and a doubly-linked list to achieve O(1) time complexity for both `Get` and `Add` operations.

*   `map[string]*list.Element`: Provides direct access to cache entries.
*   `list.List`: A doubly-linked list that maintains the order of access. The most recently used item is moved to the front, and the least recently used item is at the back, ready for eviction.


### 2. Consistent Hashing

![alt text](image-1.png)
```bash
Time â”‚ Request 1       â”‚ Request 2       â”‚ Request 3       â”‚ ... â”‚ Request 100
â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  1  â”‚ Check cache     â”‚ Check cache     â”‚ Check cache     â”‚     â”‚ Check cache
  2  â”‚ âŒ MISS         â”‚ âŒ MISS         â”‚ âŒ MISS         â”‚     â”‚ âŒ MISS
  3  â”‚ Query DB ğŸ”¥     â”‚ Query DB ğŸ”¥     â”‚ Query DB ğŸ”¥     â”‚     â”‚ Query DB ğŸ”¥
  4  â”‚ DB processing   â”‚ DB processing   â”‚ DB processing   â”‚     â”‚ DB processing
  5  â”‚ Get result      â”‚ Get result      â”‚ Get result      â”‚     â”‚ Get result
  6  â”‚ Set cache       â”‚ Set cache       â”‚ Set cache       â”‚     â”‚ Set cache

```

**Problem**: 100 identical DB queries executed simultaneously! ğŸ’¥
```
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   Cache     â”‚
         â”‚  (expired)  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â”‚ 100 requests miss cache
                â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Database   â”‚ â† ğŸ’¥ 100 concurrent queries!
         â”‚  OVERLOAD!  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## **âœ… WITH Singleflight (Problem Solved!)**
```
Time â”‚ Request 1          â”‚ Request 2          â”‚ Request 3          â”‚ ... â”‚ Request 100
â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  1  â”‚ Check cache        â”‚ Check cache        â”‚ Check cache        â”‚     â”‚ Check cache
  2  â”‚ âŒ MISS            â”‚ âŒ MISS            â”‚ âŒ MISS            â”‚     â”‚ âŒ MISS
  3  â”‚ g.mu.Lock()        â”‚ g.mu.Lock() â³     â”‚ g.mu.Lock() â³     â”‚     â”‚ g.mu.Lock() â³
  4  â”‚ g.m[key] NOT found â”‚ (blocked...)       â”‚ (blocked...)       â”‚     â”‚ (blocked...)
  5  â”‚ c = new(call)      â”‚                    â”‚                    â”‚     â”‚
  6  â”‚ g.m[key] = c       â”‚                    â”‚                    â”‚     â”‚
  7  â”‚ g.mu.Unlock()      â”‚                    â”‚                    â”‚     â”‚
  8  â”‚ Query DB ğŸ”¥        â”‚ g.mu.Lock()        â”‚ g.mu.Lock() â³     â”‚     â”‚ g.mu.Lock() â³
  9  â”‚ DB processing...   â”‚ g.m[key] FOUND! âœ“  â”‚ (blocked...)       â”‚     â”‚ (blocked...)
 10  â”‚                    â”‚ c.wg.Wait() â³     â”‚                    â”‚     â”‚
 11  â”‚                    â”‚ (waiting...)       â”‚ g.mu.Lock()        â”‚     â”‚ g.mu.Lock() â³
 12  â”‚                    â”‚                    â”‚ g.m[key] FOUND! âœ“  â”‚     â”‚
 13  â”‚                    â”‚                    â”‚ c.wg.Wait() â³     â”‚     â”‚
 14  â”‚ Get result âœ“       â”‚                    â”‚ (waiting...)       â”‚     â”‚ (waiting...)
 15  â”‚ c.wg.Done()        â”‚ (unblocked!)       â”‚ (unblocked!)       â”‚     â”‚ (unblocked!)
 16  â”‚                    â”‚ return result      â”‚ return result      â”‚     â”‚ return result
```

**Result**: Only **1 DB query** for 100 requests! ğŸ‰
```
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   Cache     â”‚
         â”‚  (expired)  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â”‚ 100 requests miss cache
                â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Singleflightâ”‚
         â”‚   Group     â”‚ â† Deduplicates to 1 request
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â”‚ Only 1 query!
                â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Database   â”‚ â† ğŸ˜Š Happy!
         â”‚    (OK)     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## **Detailed Flow Chart**
```
Request comes in
      â”‚
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Check Cache  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â†“
  Cache Hit? â”€â”€â”€â”€Yesâ”€â”€â”€â†’ Return cached value
      â”‚
      No
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  g.mu.Lock()         â”‚  â† CRITICAL SECTION
â”‚  Check g.m[key]      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â†“
   Key exists in g.m?
      â”‚
      â”œâ”€â”€â”€â”€â”€Yesâ”€â”€â”€â”€â”€â†’ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚               â”‚ g.mu.Unlock()    â”‚
      â”‚               â”‚ c.wg.Wait()      â”‚ â† Wait for first request
      â”‚               â”‚ return c.val     â”‚
      â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      No (I'm first!)
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ c = new(call)        â”‚
â”‚ c.wg.Add(1)          â”‚
â”‚ g.m[key] = c         â”‚  â† Register myself
â”‚ g.mu.Unlock()        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Query Database       â”‚  â† Only first request does this
â”‚ c.val = result       â”‚
â”‚ c.wg.Done()          â”‚  â† Unblock all waiters
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ delete(g.m, key)     â”‚  â† Cleanup
â”‚ return result        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## **Comparison Chart**

| Metric | Without Singleflight | With Singleflight |
|--------|---------------------|-------------------|
| **DB Queries** | 100 | 1 |
| **DB Load** | ğŸ’¥ Overload | ğŸ˜Š Normal |
| **Response Time** | Slow (DB overwhelmed) | Fast (only 1 query) |
| **Cache Breakdown** | âŒ Happens | âœ… Prevented |

---


maps keys to a space of 2^32, connecting the beginning and end of this number range to form a ring. When adding or deleting nodes, only a small portion of data near that node needs to be relocated, rather than needing to relocate all the data. This solves the * cache avalanche  and cache skew problem *.

- Calculate the hash value of nodes/machines (typically using the node's name, number, and IP address) and place them on the ring.
- Calculate the hash value of the key and place it on the ring. Moving clockwise, the first node encountered is the node/machine that should be selected.

To distribute keys across multiple nodes without causing a massive reshuffle when the cluster size changes, we use a consistent hashing algorithm.

*   **Hash Ring**: All cache nodes (peers) are mapped onto a virtual hash ring.
*   **Virtual Nodes**: To ensure a more uniform distribution of keys, each real node is represented by multiple "virtual nodes" on the ring.
*   **Key Mapping**: To find which node owns a key, we hash the key and find the first node that appears clockwise on the ring.

This approach ensures that when a node is added or removed, only a small fraction of keys need to be remapped.


#### cache breakdown problem
- when test for 3 curl, becuase of hash function, all request calling 8001 host
![test](image-3.png)
- when test for 100, 000, it caused cache breakdown problem
![cache breakdown for 100,000 reques for 8001](image-2.png)

### 3. Single-Flight Execution
![alt text](image-4.png)
The `singleflight` pattern is a crucial optimization to prevent cache breakdown (also known as a cache stampede or thundering herd).

A cache breakdown occurs when a popular, uncached item is requested by thousands of clients simultaneously. All these requests miss the cache and hit the backend database at the same time, potentially causing it to crash.

The `singleflight` group ensures that for any given key, only **one** request is sent to the backend data source (or a remote peer). All other concurrent requests for the same key will wait for the first one to complete and will then share its result. This effectively coalesces multiple identical requests into a single one.

---

## The Cache Breakdown Problem & Solution

In a high-concurrency environment, if a cached value expires or is not yet present, multiple requests can simultaneously miss the cache and proceed to query the slow backend database for the same data.

**Without `singleflight`**, our system would suffer from this problem, leading to redundant database queries as shown below. Each `[SlowDB] search key` log represents a database hit.

```
2025/10/20 13:25:21 [SlowDB] search key Tom
2025/10/20 13:25:21 [GeeCache] hit
2025/10/20 13:25:21 [SlowDB] search key Tom
630630630
```

**With `singleflight`**, the system is protected. The first request triggers the database lookup, while subsequent requests for the same key wait and share the result. This results in only one database hit, significantly reducing the load on the backend.

```
2025/10/20 13:18:12 [Server http://localhost:8003] Pick peer http://localhost:8001
2025/10/20 13:18:12 [Server http://localhost:8001] GET /_geecache/scores/Tom
2025/10/20 13:18:12 [SlowDB] search key Tom
2025/10/20 13:18:12 [GeeCache] hit
2025/10/20 13:18:12 [GeeCache] hit
630630630
```

---

## Project Structure

```
Distributed-Caching-Optimization/
â”œâ”€â”€ consistenthash/
â”‚   â””â”€â”€ consistenthash.go   # Consistent hashing implementation
â”œâ”€â”€ lru/
â”‚   â””â”€â”€ lru.go          # Core LRU cache data structure
â”€â”€ singleflight/
â”‚   â””â”€â”€ singleflight.go # Request coalescing logic
â”œâ”€â”€ geecache/  
â”‚   â”œâ”€â”€ byteview.go         # Read-only byte view for cache values
â”‚   â”œâ”€â”€ cache.go            # Thread-safe wrapper for the LRU cache
â”‚   â”œâ”€â”€ geecache.go         # Main group logic and peer interaction
â”‚   â””â”€â”€ http.go             # HTTP server for peer-to-peer communication
â”œâ”€â”€ main.go                 # Main application to start servers
â””â”€â”€ run.sh                  # Script to build and run a demo cluster
```

## How to Run

1.  **Build the application**:
    ```bash
    go build -o server
    ```
2.  **Run the cluster**:
    The `run.sh` script starts three cache nodes on ports `8001`, `8002`, and `8003`, along with a frontend API server on port `9999`.
    ```bash
    ./run.sh
    ```
3.  **Test the API**:
    You can now query the cache via the API server.
    ```bash
    # This will either hit the cache or fetch from the slow DB
    $ curl "http://localhost:9999/api?key=Tom"
    630

    # This key does not exist in the DB
    $ curl "http://localhost:9999/api?key=unknown"
    unknown not exist
    ```

## Final Service
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BEST USE CASES                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                            â”‚
â”‚  1ï¸âƒ£  REAL-TIME LEADERBOARDS / SCORES                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                    â”‚
â”‚  â€¢ Gaming platforms (millions of players)                 â”‚
â”‚  â€¢ Sports apps (live rankings)                            â”‚
â”‚  â€¢ Fitness trackers (activity feeds)                      â”‚
â”‚                                                            â”‚
â”‚  Why ideal:                                                â”‚
â”‚  âœ… Hot data (leaderboard queries 1000s/sec)              â”‚
â”‚  âœ… Consistent hashing fits {userId: score}               â”‚
â”‚  âœ… Singleflight prevents DB hammer on popular players    â”‚
â”‚  âœ… Frequent updates (invalidation via Kafka)             â”‚
â”‚  âœ… High tolerance for eventual consistency (~100ms)      â”‚
â”‚                                                            â”‚
â”‚  Example Load:                                             â”‚
â”‚  - 100k daily users, 50k concurrent                       â”‚
â”‚  - 500k score lookups/hour                                â”‚
â”‚  - Your system: ğŸ’° $5k/month (vs $50k for managed cache) â”‚
â”‚                                                            â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚                                                            â”‚
â”‚  2ï¸âƒ£  E-COMMERCE PRODUCT CATALOGS                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                    â”‚
â”‚  â€¢ Shopping carts (1-2k RPS)                              â”‚
â”‚  â€¢ Product metadata (descriptions, prices)                â”‚
â”‚  â€¢ Inventory counts (frequently updated)                  â”‚
â”‚                                                            â”‚
â”‚  Why ideal:                                                â”‚
â”‚  âœ… Medium-hot data (millions of SKUs, subset cached)     â”‚
â”‚  âœ… Singleflight prevents thundering herd on flash sales  â”‚
â”‚  âœ… Multi-AZ ensures uptime (cart never goes down)        â”‚
â”‚  âœ… Raft handles distributed cart replica sync            â”‚
â”‚                                                            â”‚
â”‚  Example Load:                                             â”‚
â”‚  - 10M SKUs, 10k hot items                                â”‚
â”‚  - 5k concurrent users in cart                            â”‚
â”‚  - Your system: ğŸ’° $8k/month                              â”‚
â”‚                                                            â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚                                                            â”‚
â”‚  3ï¸âƒ£  API RATE LIMITING / QUOTA TRACKING                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                    â”‚
â”‚  â€¢ API gateway (track per-user rate limits)               â”‚
â”‚  â€¢ SaaS metering (API calls per subscription tier)        â”‚
â”‚  â€¢ DDoS protection (track request IPs)                    â”‚
â”‚                                                            â”‚
â”‚  Why ideal:                                                â”‚
â”‚  âœ… Requires instant cross-node consistency               â”‚
â”‚  âœ… High throughput (millions of quota checks/sec)        â”‚
â”‚  âœ… Raft ensures no double-counting across nodes          â”‚
â”‚  âœ… Sub-millisecond latency critical                      â”‚
â”‚                                                            â”‚
â”‚  Example Load:                                             â”‚
â”‚  - 10k API clients making 100 req/sec each                â”‚
â”‚  - 1M quota checks/sec                                    â”‚
â”‚  - Your system: ğŸ’° $6k/month (vs $100k+ for managed)    â”‚
â”‚                                                            â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚                                                            â”‚
â”‚  4ï¸âƒ£  SESSION STORAGE (User Login State)                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                    â”‚
â”‚  â€¢ User authentication tokens                             â”‚
â”‚  â€¢ Login sessions (device fingerprints)                   â”‚
â”‚  â€¢ 2FA state (temporary codes)                            â”‚
â”‚                                                            â”‚
â”‚  Why ideal:                                                â”‚
â”‚  âœ… Medium lifespan (hours â†’ days)                        â”‚
â”‚  âœ… Must survive node failures (Raft quorum)              â”‚
â”‚  âœ… High availability (concurrent logins spike)           â”‚
â”‚  âœ… Cost-effective (vs. Redis Enterprise)                 â”‚
â”‚                                                            â”‚
â”‚  Example Load:                                             â”‚
â”‚  - 100M registered users, 5% active                       â”‚
â”‚  - 5M session lookups/hour                                â”‚
â”‚  - Your system: ğŸ’° $4k/month                              â”‚
â”‚                                                            â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚                                                            â”‚
â”‚  5ï¸âƒ£  DISTRIBUTED FEATURE FLAGS / CONFIG                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                â”‚
â”‚  â€¢ A/B test assignments (consistent per user)             â”‚
â”‚  â€¢ Feature flags (canary rollouts)                        â”‚
â”‚  â€¢ Regional config (serve different content)              â”‚
â”‚                                                            â”‚
â”‚  Why ideal:                                                â”‚
â”‚  âœ… Consistent hashing = same user always gets same flag  â”‚
â”‚  âœ… Quick updates (Kafka invalidation)                    â”‚
â”‚  âœ… Raft ensures no conflicting assignments               â”‚
â”‚  âœ… Scales to billions of feature flag evals              â”‚
â”‚                                                            â”‚
â”‚  Example Load:                                             â”‚
â”‚  - 1B monthly active users                                â”‚
â”‚  - 50k feature flag lookups/sec                           â”‚
â”‚  - Your system: ğŸ’° $12k/month (vs $200k+ LaunchDarkly)  â”‚
â”‚                                                            â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚                                                            â”‚
â”‚  6ï¸âƒ£  RECOMMENDATION ENGINE CACHE                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                    â”‚
â”‚  â€¢ ML model predictions (user embeddings)                 â”‚
â”‚  â€¢ Candidate items (pre-computed top-N)                   â”‚
â”‚  â€¢ Personalization state                                  â”‚
â”‚                                                            â”‚
â”‚  Why ideal:                                                â”‚
â”‚  âœ… Cache predictions (not recompute ML every request)    â”‚
â”‚  âœ… Consistent hashing = same user â†’ same recommendations â”‚
â”‚  âœ… Singleflight prevents model overload                  â”‚
â”‚  âœ… High-performance serving (sub-10ms)                   â”‚
â”‚                                                            â”‚
â”‚  Example Load:                                             â”‚
â”‚  - 50M monthly users                                      â”‚
â”‚  - 100 candidate items / user (500M cached items)         â”‚
â”‚  - 10k recommendation requests/sec                        â”‚
â”‚  - Your system: ğŸ’° $10k/month (core recommendation tier) â”‚
â”‚                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚ Shoppers (Global)â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  AWS CloudFront (CDN)       â”‚
                    â”‚  (Static assets, origin)    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚  Application Load Balancer (HTTPS)  â”‚
                â”‚  (geecache.shop.com:443)            â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                      â”‚                      â”‚
        â–¼                      â–¼                      â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ API    â”‚            â”‚ API    â”‚            â”‚ API    â”‚
    â”‚Frontendâ”‚            â”‚Frontendâ”‚            â”‚Frontendâ”‚
    â”‚ (2-50  â”‚            â”‚ (2-50  â”‚            â”‚ (2-50  â”‚
    â”‚ Fargateâ”‚            â”‚ Fargateâ”‚            â”‚ Fargateâ”‚
    â”‚ tasks) â”‚            â”‚ tasks) â”‚            â”‚ tasks) â”‚
    â”‚        â”‚            â”‚        â”‚            â”‚        â”‚
    â”‚ Port   â”‚            â”‚ Port   â”‚            â”‚ Port   â”‚
    â”‚ 9999   â”‚            â”‚ 9999   â”‚            â”‚ 9999   â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
         â”‚ gRPC               â”‚ gRPC               â”‚ gRPC
         â”‚ (port 8001)        â”‚ (port 8001)        â”‚ (port 8001)
         â”‚                    â”‚                    â”‚
         â–¼                    â–¼                    â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚       GEECACHE CLUSTER (3-12 stateful nodes)        â”‚
    â”‚                                                      â”‚
    â”‚  Raft Consensus (port 7000):                        â”‚
    â”‚  â”œâ”€â”€ Leader election                                â”‚
    â”‚  â”œâ”€â”€ Hash ring state agreement                      â”‚
    â”‚  â””â”€â”€ Cluster membership                             â”‚
    â”‚                                                      â”‚
    â”‚  Consistent Hash Ring:                              â”‚
    â”‚  â”œâ”€â”€ {product_id â†’ node}                            â”‚
    â”‚  â”œâ”€â”€ {user_id â†’ node}                               â”‚
    â”‚  â”œâ”€â”€ {session_id â†’ node}                            â”‚
    â”‚  â””â”€â”€ Virtual nodes (150 per real node)              â”‚
    â”‚                                                      â”‚
    â”‚  LRU Cache (In-Memory):                             â”‚
    â”‚  â”œâ”€â”€ 4GB per node Ã— 6 nodes = 24GB total            â”‚
    â”‚  â”œâ”€â”€ Eviction: LRU when full                        â”‚
    â”‚  â””â”€â”€ Hit rate: ~92% on hot products                 â”‚
    â”‚                                                      â”‚
    â”‚  Singleflight (Request Coalescing):                 â”‚
    â”‚  â”œâ”€â”€ Cache miss for "Nike Shoes" â†’ 1 DB query      â”‚
    â”‚  â”œâ”€â”€ 1000 concurrent requests â†’ wait for 1          â”‚
    â”‚  â””â”€â”€ DB load: 99% reduction âœ…                      â”‚
    â”‚                                                      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”˜
               â”‚                        â”‚              â”‚
               â”‚ Cache miss            â”‚ Cache miss    â”‚ Cache miss
               â”‚ (8%)                  â”‚ (8%)          â”‚ (8%)
               â–¼                        â–¼              â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  RDS PostgreSQL (Multi-AZ)                          â”‚
    â”‚                                                      â”‚
    â”‚  Primary (us-east-1a):                              â”‚
    â”‚  â”œâ”€â”€ products table (100M rows)                      â”‚
    â”‚  â”œâ”€â”€ prices (real-time)                             â”‚
    â”‚  â”œâ”€â”€ inventory (live counts)                        â”‚
    â”‚  â””â”€â”€ Receives ~4000 queries/sec (8% misses)        â”‚
    â”‚                                                      â”‚
    â”‚  Standby (us-east-1b):                              â”‚
    â”‚  â”œâ”€â”€ Sync replication                               â”‚
    â”‚  â””â”€â”€ Auto-failover (<30s)                           â”‚
    â”‚                                                      â”‚
    â”‚  Read Replicas (optional):                          â”‚
    â”‚  â”œâ”€â”€ Analytics queries (non-critical)              â”‚
    â”‚  â””â”€â”€ Defer from primary                             â”‚
    â”‚                                                      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    Optional: Kafka KRaft (Phase 4)
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Topic: product-updates           â”‚
    â”‚ â”œâ”€â”€ When price changes: publish  â”‚
    â”‚ â”œâ”€â”€ Cache nodes: consume & evict â”‚
    â”‚ â””â”€â”€ Result: Faster invalidation  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    Observability (Prometheus + Grafana)
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Dashboard: e-commerce.grafana    â”‚
    â”œâ”€â”€ Cache hit rate: 92%            â”‚
    â”œâ”€â”€ P99 latency: 45ms              â”‚
    â”œâ”€â”€ DB qps: 4000                   â”‚
    â”œâ”€â”€ RPS: 50,000                    â”‚
    â””â”€â”€ Cost: $15k/month               â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
## Not good for
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DON'T USE THIS CACHE FOR:                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                            â”‚
â”‚  âŒ Time-Series Data (metrics, logs)                       â”‚
â”‚     Why: Raft quorum slows down high-write workloads      â”‚
â”‚     Use: InfluxDB, Prometheus instead                     â”‚
â”‚                                                            â”‚
â”‚  âŒ Full-Text Search (search indexes)                      â”‚
â”‚     Why: Not designed for complex queries                 â”‚
â”‚     Use: Elasticsearch, Opensearch                        â”‚
â”‚                                                            â”‚
â”‚  âŒ Large Objects (images, videos)                         â”‚
â”‚     Why: LRU cache limited to GB, not TB                  â”‚
â”‚     Use: S3, CDN (CloudFront)                             â”‚
â”‚                                                            â”‚
â”‚  âŒ Persistent Data Warehouse (analytics)                  â”‚
â”‚     Why: Cache evicts old data, not designed for OLAP    â”‚
â”‚     Use: Redshift, BigQuery, Snowflake                    â”‚
â”‚                                                            â”‚
â”‚  âŒ Message Queue (job processing)                         â”‚
â”‚     Why: Cache doesn't guarantee durability or ordering  â”‚
â”‚     Use: Kafka, SQS, RabbitMQ                             â”‚
â”‚                                                            â”‚
â”‚  âŒ Geo-distributed Replication (multi-region)             â”‚
â”‚     Why: Raft requires low-latency quorum (same region)  â”‚
â”‚     Use: Multi-master replication (CockroachDB)           â”‚
â”‚                                                            â”‚
â”‚  âŒ Super-Hot Real-Time Data (<1ms latency required)       â”‚
â”‚     Why: Network round-trip + Raft consensus adds latency â”‚
â”‚     Use: In-process cache, local memory                   â”‚
â”‚                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## The Clean Separation
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           RAFT (Distributed Consensus)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚ Small coordination problem:                                â”‚
â”‚ â€¢ 3-12 nodes agreeing on hash ring                         â”‚
â”‚ â€¢ Who's leader? (not the data)                             â”‚
â”‚ â€¢ Lightweight messages (KB not GB)                         â”‚
â”‚ â€¢ Quorum: majority (can lose 1 node)                       â”‚
â”‚                                                             â”‚
â”‚ RAFT DOES: âœ… Consensus on membership & config             â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                          â†“â†‘ (gRPC)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         AWS INFRASTRUCTURE (Everything Else)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚ The "boring" stuff that's hard to build:                   â”‚
â”‚ â€¢ Network isolation (VPC, subnets, security groups)        â”‚
â”‚ â€¢ Load balancing (route traffic fairly)                    â”‚
â”‚ â€¢ Auto-scaling (spin up/down instances)                    â”‚
â”‚ â€¢ Persistent storage (RDS databases)                       â”‚
â”‚ â€¢ Monitoring & alerting (CloudWatch, alarms)               â”‚
â”‚ â€¢ Cost tracking (bill by the hour)                         â”‚
â”‚ â€¢ Multi-AZ resilience (data replication)                   â”‚
â”‚ â€¢ Backups & disaster recovery                              â”‚
â”‚ â€¢ SSL/TLS security (encrypt traffic)                       â”‚
â”‚                                                             â”‚
â”‚ AWS DOES: âœ… All the infrastructure so you don't have to  â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
<img width="688" height="321" alt="image" src="https://github.com/user-attachments/assets/e4e2e52e-b7cd-419d-9809-8cf9072a25ef" />
